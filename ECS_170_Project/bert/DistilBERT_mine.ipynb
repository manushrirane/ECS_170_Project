{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQ3tY9J+Uh7alBshsrDqXT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manushrirane/ECS_170_Project/blob/main/ECS_170_Project/bert/DistilBERT_mine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTNZfgxAd5DT",
        "outputId": "87d06a40-4c49-4c88-d081-7f121d6d796d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "\n",
            "Loading tokenizer...\n",
            "Loading IMDB dataset...\n",
            "Train examples: 25000, Eval examples: 25000\n",
            "\n",
            "Label distribution:\n",
            "  Train: [12500 12500]\n",
            "  Eval : [12500 12500]\n",
            "\n",
            "Tokenizing... (this may take a minute)\n",
            "\n",
            "--- üöÄ Setup Complete! ---\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets scikit-learn peft\n",
        "\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    DistilBertTokenizer,\n",
        "    DistilBertForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "\n",
        "# Reproducibility\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "\n",
        "# Device Info  (UPGRADE #1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Running on CPU (no GPU available)\")\n",
        "\n",
        "\n",
        "\n",
        "# Parameter Counting Utility\n",
        "def count_parameters(model, trainable_only: bool = False):\n",
        "    if trainable_only:\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "\n",
        "# Load model + tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "print(\"\\nLoading tokenizer...\")\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"Loading IMDB dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "print(f\"Train examples: {len(train_dataset)}, Eval examples: {len(eval_dataset)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Dataset Label Distribution  (UPGRADE #2)\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(\"  Train:\", np.bincount(train_dataset[\"label\"]))\n",
        "print(\"  Eval :\", np.bincount(eval_dataset[\"label\"]))\n",
        "\n",
        "\n",
        "\n",
        "# Tokenization\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "    )\n",
        "\n",
        "print(\"\\nTokenizing... (this may take a minute)\")\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_eval_dataset = tokenized_eval_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "tokenized_train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "tokenized_eval_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Reset GPU Peak Memory  (UPGRADE #3)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "print(\"\\n--- üöÄ Setup Complete! ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "import torch\n",
        "\n",
        "\n",
        "# 1. Compute Cost Summary  (Improved)\n",
        "def compute_cost_summary(model, train_time_seconds, trainable_params=None):\n",
        "    print(\"\\n==================== Compute Cost ====================\")\n",
        "\n",
        "    # ---- Parameter counts ----\n",
        "    total_params = count_parameters(model)\n",
        "    trainable_params = trainable_params or count_parameters(model, True)\n",
        "\n",
        "    print(f\"Total Parameters:        {total_params:,}\")\n",
        "    print(f\"Trainable Parameters:    {trainable_params:,}\")\n",
        "\n",
        "    # ---- Training time ----\n",
        "    print(f\"Training Time (seconds): {train_time_seconds:.2f}\")\n",
        "\n",
        "    # ---- GPU Memory ----\n",
        "    if torch.cuda.is_available():\n",
        "        mem = torch.cuda.max_memory_allocated() / 1e6\n",
        "        print(f\"Max GPU Memory (MB):     {mem:.2f}\")\n",
        "        torch.cuda.reset_peak_memory_stats()   # reset for next experiment\n",
        "    else:\n",
        "        print(\"Max GPU Memory (MB):     CPU-only (no GPU)\")\n",
        "\n",
        "    # ---- FLOPs Estimate ----\n",
        "    flops = total_params * 2\n",
        "    print(f\"Estimated FLOPs:         {flops / 1e9:.3f} GFLOPs\")\n",
        "\n",
        "    print(\"=====================================================\")\n",
        "\n",
        "\n",
        "\n",
        "# 2. Metrics for HuggingFace Trainer (LoRA)\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "\n",
        "    return {\"accuracy\": acc, \"f1_score\": f1}\n",
        "\n",
        "\n",
        "\n",
        "# 3. Error Analysis Utility (Improved)\n",
        "def error_analysis(model, dataset, tokenizer, max_examples=5):\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_texts = []\n",
        "\n",
        "    # ---- Loop over dataset ----\n",
        "    for item in dataset:\n",
        "        input_ids = item[\"input_ids\"].unsqueeze(0).to(device)\n",
        "        attention_mask = item[\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        label = item[\"labels\"].item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            ).logits\n",
        "\n",
        "            # FIX C: safer GPU ‚Üí CPU detach\n",
        "            pred = torch.argmax(logits.cpu().detach(), dim=1).item()\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_labels.append(label)\n",
        "\n",
        "        decoded = tokenizer.decode(\n",
        "            item[\"input_ids\"],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        all_texts.append(decoded)\n",
        "\n",
        "    # ---- Confusion Matrix ----\n",
        "    print(\"\\n================ Confusion Matrix ================\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "\n",
        "    # ---- Classification Report ----\n",
        "    print(\"\\n=============== Classification Report ===============\")\n",
        "    print(classification_report(all_labels, all_preds, digits=4))\n",
        "\n",
        "    # ---- Misclassified Examples ----\n",
        "    print(\"\\n=============== Misclassified Examples ===============\\n\")\n",
        "\n",
        "    errors = [\n",
        "        (text[:300], pred, label)\n",
        "        for text, pred, label in zip(all_texts, all_preds, all_labels)\n",
        "        if pred != label\n",
        "    ]\n",
        "\n",
        "    if len(errors) == 0:\n",
        "        print(\"No misclassified examples ‚Äî model predicted everything correctly!\")\n",
        "        return\n",
        "\n",
        "    for i, (text, pred, label) in enumerate(errors[:max_examples]):\n",
        "        print(f\"Example #{i+1}:\")\n",
        "        print(\"Text:\", text)\n",
        "        print(\"Predicted:\", pred, \"| True:\", label)\n",
        "        print(\"------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "xI1x4gDld8wj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"--- Starting Baseline (Path C) Evaluation ---\")\n",
        "set_seed(SEED)\n",
        "\n",
        "baseline_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=2\n",
        ").to(device)\n",
        "baseline_model.eval()   # <-- Fixed\n",
        "\n",
        "print(\"Total params (baseline):\", count_parameters(baseline_model))\n",
        "print(\"Trainable params (baseline):\", count_parameters(baseline_model, True))\n",
        "\n",
        "# Reset GPU peak memory counter for accurate compute cost\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "\n",
        "def evaluate_model_on_loader(model, eval_dataset):\n",
        "    model.eval()\n",
        "    dataloader = DataLoader(eval_dataset, batch_size=32)\n",
        "\n",
        "    all_labels, all_preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {\n",
        "                k: v.to(device)\n",
        "                for k, v in batch.items()\n",
        "                if k in [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "            }\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"],\n",
        "                \"attention_mask\": batch[\"attention_mask\"],\n",
        "            }\n",
        "            labels = batch[\"labels\"]\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    return {\"accuracy\": acc, \"f1_score\": f1}\n",
        "\n",
        "\n",
        "start_time_baseline = time.time()\n",
        "baseline_results = evaluate_model_on_loader(baseline_model, tokenized_eval_dataset)\n",
        "end_time_baseline = time.time()\n",
        "baseline_time = end_time_baseline - start_time_baseline\n",
        "\n",
        "print(\"\\n--- Final Baseline (Path C) Results ---\")\n",
        "print(f\"Accuracy: {baseline_results['accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {baseline_results['f1_score']:.4f}\")\n",
        "print(f\"Total Time: {baseline_time:.2f} s\")\n",
        "\n",
        "\n",
        "\n",
        "#  Baseline Compute Cost\n",
        "compute_cost_summary(\n",
        "    baseline_model,\n",
        "    baseline_time,\n",
        "    trainable_params=count_parameters(baseline_model, True)\n",
        ")\n",
        "\n",
        "#  Baseline Error Analysis\n",
        "print(\"\\n--- Baseline (Path C) Error Analysis ---\")\n",
        "error_analysis(\n",
        "    baseline_model,\n",
        "    tokenized_eval_dataset,\n",
        "    tokenizer,\n",
        "    max_examples=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt05vOGed-vz",
        "outputId": "6cb009e1-276e-44ae-fb76-fec56ea5bff6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Baseline (Path C) Evaluation ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params (baseline): 66955010\n",
            "Trainable params (baseline): 66955010\n",
            "\n",
            "--- Final Baseline (Path C) Results ---\n",
            "Accuracy: 0.4094\n",
            "F1-Score: 0.4060\n",
            "Total Time: 179.93 s\n",
            "\n",
            "==================== Compute Cost ====================\n",
            "Total Parameters:        66,955,010\n",
            "Trainable Parameters:    66,955,010\n",
            "Training Time (seconds): 179.93\n",
            "Max GPU Memory (MB):     2275.81\n",
            "Estimated FLOPs:         0.134 GFLOPs\n",
            "=====================================================\n",
            "\n",
            "--- Baseline (Path C) Error Analysis ---\n",
            "\n",
            "================ Confusion Matrix ================\n",
            "[[4179 8321]\n",
            " [6445 6055]]\n",
            "\n",
            "=============== Classification Report ===============\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.3934    0.3343    0.3614     12500\n",
            "           1     0.4212    0.4844    0.4506     12500\n",
            "\n",
            "    accuracy                         0.4094     25000\n",
            "   macro avg     0.4073    0.4094    0.4060     25000\n",
            "weighted avg     0.4073    0.4094    0.4060     25000\n",
            "\n",
            "\n",
            "=============== Misclassified Examples ===============\n",
            "\n",
            "Example #1:\n",
            "Text: worth the entertainment value of a rental, especially if you like action movies. this one features the usual car chases, fights with the great van damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. all of this is entertaining and competently handled bu\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #2:\n",
            "Text: its a totally average film with a few semi - alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave th\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #3:\n",
            "Text: first off let me say, if you haven't enjoyed a van damme movie since bloodsport, you probably will not like this movie. most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are. this movie is much better than any of the movies the other acti\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #4:\n",
            "Text: i had high hopes for this one until they changed the name to'the shepherd : border patrol, the lamest movie name ever, what was wrong with just'the shepherd '. this is a by the numbers action flick that tips its hat at many classic van damme films. there is a nice bit of action in a bar which remind\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #5:\n",
            "Text: it actually pains me to say it, but this movie was horrible on every level. the blame does not lie entirely with van damme as you can see he tried his best, but let's face it, he's almost fifty, how much more can you ask of him? i find it so hard to believe that the same people who put together undi\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"transformers>=4.30.0\" \"datasets\" \"peft\" -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y16fiVHdt-yW",
        "outputId": "6e42c13d-ac01-4eba-cbca-ecf2a7e7c9e0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================ LoRA Fine-Tuning (Path A) ================\\n\")\n",
        "\n",
        "from transformers import TrainingArguments as HFTrainingArguments, Trainer\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# Load base model\n",
        "base_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=2\n",
        ")\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"],\n",
        "    lora_dropout=0.0,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\",\n",
        ")\n",
        "\n",
        "# Apply LoRA\n",
        "lora_model = get_peft_model(base_model, lora_config)\n",
        "lora_model = lora_model.to(device)\n",
        "\n",
        "print(\"Total params (LoRA-wrapped):\", count_parameters(lora_model))\n",
        "print(\"Trainable params (LoRA):\", count_parameters(lora_model, True))\n",
        "\n",
        "# Training arguments for Transformers\n",
        "training_args = HFTrainingArguments(\n",
        "    output_dir=\"./results/distilbert-lora\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"--- Starting LoRA Fine-Tuning (Path A) ---\")\n",
        "start_time_lora = time.time()\n",
        "trainer.train()\n",
        "end_time_lora = time.time()\n",
        "lora_time = end_time_lora - start_time_lora\n",
        "\n",
        "print(\"--- Evaluating LoRA Model ---\")\n",
        "lora_eval = trainer.evaluate()\n",
        "\n",
        "print(\"\\n--- Final LoRA (Path A) Results ---\")\n",
        "print(f\"Accuracy: {lora_eval['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {lora_eval['eval_f1_score']:.4f}\")\n",
        "print(f\"Total Time: {lora_time:.2f} s\")\n",
        "\n",
        "\n",
        "#  Compute Cost Summary (LoRA)\n",
        "compute_cost_summary(\n",
        "    lora_model,\n",
        "    lora_time,\n",
        "    trainable_params=count_parameters(lora_model, True)\n",
        ")\n",
        "\n",
        "\n",
        "#  LoRA Error Analysis\n",
        "print(\"\\n--- LoRA (Path A) Error Analysis ---\")\n",
        "error_analysis(\n",
        "    lora_model,\n",
        "    tokenized_eval_dataset,\n",
        "    tokenizer,\n",
        "    max_examples=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bdAP5V9UeAiH",
        "outputId": "cd32b9a2-a164-47b1-f15b-bea7d52d70d1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ LoRA Fine-Tuning (Path A) ================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params (LoRA-wrapped): 67842052\n",
            "Trainable params (LoRA): 887042\n",
            "--- Starting LoRA Fine-Tuning (Path A) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4689/4689 29:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.259024</td>\n",
              "      <td>0.894760</td>\n",
              "      <td>0.894601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.227300</td>\n",
              "      <td>0.232764</td>\n",
              "      <td>0.906680</td>\n",
              "      <td>0.906665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.184500</td>\n",
              "      <td>0.242056</td>\n",
              "      <td>0.909360</td>\n",
              "      <td>0.909349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating LoRA Model ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 03:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final LoRA (Path A) Results ---\n",
            "Accuracy: 0.9094\n",
            "F1-Score: 0.9093\n",
            "Total Time: 1774.24 s\n",
            "\n",
            "==================== Compute Cost ====================\n",
            "Total Parameters:        67,842,052\n",
            "Trainable Parameters:    887,042\n",
            "Training Time (seconds): 1774.24\n",
            "Max GPU Memory (MB):     2261.05\n",
            "Estimated FLOPs:         0.136 GFLOPs\n",
            "=====================================================\n",
            "\n",
            "--- LoRA (Path A) Error Analysis ---\n",
            "\n",
            "================ Confusion Matrix ================\n",
            "[[11231  1269]\n",
            " [  997 11503]]\n",
            "\n",
            "=============== Classification Report ===============\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9185    0.8985    0.9084     12500\n",
            "           1     0.9006    0.9202    0.9103     12500\n",
            "\n",
            "    accuracy                         0.9094     25000\n",
            "   macro avg     0.9096    0.9094    0.9093     25000\n",
            "weighted avg     0.9096    0.9094    0.9093     25000\n",
            "\n",
            "\n",
            "=============== Misclassified Examples ===============\n",
            "\n",
            "Example #1:\n",
            "Text: first off let me say, if you haven't enjoyed a van damme movie since bloodsport, you probably will not like this movie. most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are. this movie is much better than any of the movies the other acti\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #2:\n",
            "Text: isaac florentine has made some of the best western martial arts action movies ever produced. in particular us seals 2, cold harvest, special forces and undisputed 2 are all action classics. you can tell isaac has a real passion for the genre and his films are always eventful, creative and sharp affa\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #3:\n",
            "Text: ben, ( rupert grint ), is a deeply unhappy adolescent, the son of his unhappily married parents. his father, ( nicholas farrell ), is a vicar and his mother, ( laura linney ), is... well, let's just say she's a somewhat hypocritical soldier in jesus'army. it's only when he takes a summer job as an a\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #4:\n",
            "Text: low budget horror movie. if you don't raise your expectations too high, you'll probably enjoy this little flick. beginning and end are pretty good, middle drags at times and seems to go nowhere for long periods as we watch the goings on of the insane that add atmosphere but do not advance the plot. \n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n",
            "Example #5:\n",
            "Text: dr stephens ( micheal harvey ) runs a mental asylum. he has a different approach to the insane. he conducts unorthodox methods of treatment. he treats everyone like family, there are no locks on the patients doors and he lets some of the inmates act out their twisted fantasies. he lets sergeant jaff\n",
            "Predicted: 1 | True: 0\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#        CACHE DISTILBERT EMBEDDINGS FOR ES (FAST!)\n",
        "# ============================================================\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "print(\"Caching BERT embeddings for ES...\")\n",
        "\n",
        "# Load frozen encoder\n",
        "encoder = DistilBertForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=2\n",
        ").distilbert.to(device)\n",
        "encoder.eval()\n",
        "\n",
        "def embed_dataset(tokenized_dataset):\n",
        "    all_embeddings = []\n",
        "    all_labels = []\n",
        "\n",
        "    loader = DataLoader(tokenized_dataset, batch_size=64)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            hidden = encoder(input_ids=input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
        "            #             ^ take CLS token hidden state (768 dims)\n",
        "\n",
        "            all_embeddings.append(hidden.cpu())\n",
        "            all_labels.append(batch[\"labels\"].cpu())\n",
        "\n",
        "    embeddings = torch.cat(all_embeddings)\n",
        "    labels = torch.cat(all_labels)\n",
        "\n",
        "    print(f\"Cached {embeddings.shape[0]} embeddings of dim {embeddings.shape[1]}\")\n",
        "    return TensorDataset(embeddings, labels)\n",
        "\n",
        "# Create cached datasets\n",
        "es_train_dataset = embed_dataset(tokenized_train_dataset)\n",
        "es_eval_dataset  = embed_dataset(tokenized_eval_dataset)\n",
        "\n",
        "print(\"Caching complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovKar92t7QRG",
        "outputId": "f5ecb0f3-c74a-4dc5-89ec-abe0d01e87a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching BERT embeddings for ES...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cached 25000 embeddings of dim 768\n",
            "Cached 25000 embeddings of dim 768\n",
            "Caching complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#                  Evolution Strategies (Path B) ‚Äî FINAL\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"\\n================ Evolution Strategies (Path B, Cached) ================\\n\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Evaluate ES classifier on cached eval embeddings\n",
        "def evaluate_es_classifier(model, eval_dataset):\n",
        "    model.eval()\n",
        "    loader = DataLoader(eval_dataset, batch_size=64)\n",
        "\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for emb, y in loader:\n",
        "            emb = emb.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(emb)\n",
        "            pred = torch.argmax(logits, dim=1)\n",
        "\n",
        "            preds.append(pred.cpu())\n",
        "            labels.append(y.cpu())\n",
        "\n",
        "    preds = torch.cat(preds).numpy()\n",
        "    labels = torch.cat(labels).numpy()\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1_score\": f1_score(labels, preds, average=\"weighted\")\n",
        "    }\n",
        "\n",
        "\n",
        "#  ES classifier head\n",
        "class ESClassifier(nn.Module):\n",
        "    def __init__(self, hidden=768, num_labels=2):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(hidden, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "# Run ES with cached embeddings\n",
        "def run_es_once(\n",
        "    seed,\n",
        "    num_iterations=300,\n",
        "    population_size=20,\n",
        "    learning_rate=1e-4,\n",
        "    noise_std=0.02,\n",
        "    reward_batches=5,\n",
        "):\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    model = ESClassifier().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = DataLoader(es_train_dataset, batch_size=32, shuffle=True)\n",
        "    train_iter = iter(train_loader)\n",
        "\n",
        "    print(f\"[ES] Seed {seed} | Params={count_parameters(model):,}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "\n",
        "        # ---- Sample a few batches for reward ----\n",
        "        batches = []\n",
        "        for _ in range(reward_batches):\n",
        "            try:\n",
        "                emb, y = next(train_iter)\n",
        "            except StopIteration:\n",
        "                train_iter = iter(train_loader)\n",
        "                emb, y = next(train_iter)\n",
        "\n",
        "            batches.append((emb.to(device), y.to(device)))\n",
        "\n",
        "        original = {n: p.clone() for n, p in model.named_parameters()}\n",
        "        rewards = []\n",
        "        noises = []\n",
        "\n",
        "        # ---- Population loop ----\n",
        "        for _ in range(population_size):\n",
        "            noise = {n: torch.randn_like(p) * noise_std for n, p in original.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for n, p in model.named_parameters():\n",
        "                    p.data = original[n] + noise[n]\n",
        "\n",
        "            losses = []\n",
        "            with torch.no_grad():\n",
        "                for emb, y in batches:\n",
        "                    logits = model(emb)\n",
        "                    loss = criterion(logits, y)\n",
        "                    losses.append(loss)\n",
        "\n",
        "            rewards.append(-torch.stack(losses).mean().item())\n",
        "            noises.append(noise)\n",
        "\n",
        "        rewards = torch.tensor(rewards)\n",
        "        if rewards.std() > 1e-6:\n",
        "            rewards = (rewards - rewards.mean()) / rewards.std()\n",
        "\n",
        "        # Reset model to original\n",
        "        with torch.no_grad():\n",
        "            for n, p in model.named_parameters():\n",
        "                p.data = original[n]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ---- Gradient estimation ----\n",
        "        for r, noise in zip(rewards, noises):\n",
        "            for n, p in model.named_parameters():\n",
        "                if p.grad is None:\n",
        "                    p.grad = torch.zeros_like(p)\n",
        "                p.grad += (noise[n] * r) / (population_size * noise_std)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if iteration % 20 == 0:\n",
        "            print(f\"[ES] Iter {iteration}/{num_iterations}\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    results = evaluate_es_classifier(model, es_eval_dataset)\n",
        "\n",
        "    # FIXED PRINT LINE (now shows F1)\n",
        "    print(\n",
        "        f\"[ES] Seed {seed} | Acc={results['accuracy']:.4f} \"\n",
        "        f\"| F1={results['f1_score']:.4f} | Time={total_time:.2f}s\"\n",
        "    )\n",
        "\n",
        "    return results, total_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Puejx4veFpT",
        "outputId": "6a444217-34a6-41a4-9359-38bb0e46c4b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Evolution Strategies (Path B, Cached) ================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Run multiple ES runs (average of 3 seeds)\n",
        "es_summary = run_es_multiple_times(\n",
        "    seeds=(0, 1, 2),\n",
        "    num_iterations=300,\n",
        "    population_size=20,\n",
        "    learning_rate=1e-4,\n",
        "    noise_std=0.02,\n",
        "    reward_batches=5\n",
        ")\n",
        "\n",
        "print(\"\\n=== ES Summary ===\")\n",
        "print(es_summary)"
      ],
      "metadata": {
        "id": "iGKuRZfZmf5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d4a0d3-2490-4ab7-d2ea-ac1d5304168a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Multi-run ES on seeds: (0, 1, 2)\n",
            "[ES] Seed 0 | Params=1,538\n",
            "[ES] Iter 0/300\n",
            "[ES] Iter 20/300\n",
            "[ES] Iter 40/300\n",
            "[ES] Iter 60/300\n",
            "[ES] Iter 80/300\n",
            "[ES] Iter 100/300\n",
            "[ES] Iter 120/300\n",
            "[ES] Iter 140/300\n",
            "[ES] Iter 160/300\n",
            "[ES] Iter 180/300\n",
            "[ES] Iter 200/300\n",
            "[ES] Iter 220/300\n",
            "[ES] Iter 240/300\n",
            "[ES] Iter 260/300\n",
            "[ES] Iter 280/300\n",
            "[ES] Seed 0 | Acc=0.5000 | F1=0.3333 | Time=4.53s\n",
            "[ES] Seed 1 | Params=1,538\n",
            "[ES] Iter 0/300\n",
            "[ES] Iter 20/300\n",
            "[ES] Iter 40/300\n",
            "[ES] Iter 60/300\n",
            "[ES] Iter 80/300\n",
            "[ES] Iter 100/300\n",
            "[ES] Iter 120/300\n",
            "[ES] Iter 140/300\n",
            "[ES] Iter 160/300\n",
            "[ES] Iter 180/300\n",
            "[ES] Iter 200/300\n",
            "[ES] Iter 220/300\n",
            "[ES] Iter 240/300\n",
            "[ES] Iter 260/300\n",
            "[ES] Iter 280/300\n",
            "[ES] Seed 1 | Acc=0.5000 | F1=0.3333 | Time=4.47s\n",
            "[ES] Seed 2 | Params=1,538\n",
            "[ES] Iter 0/300\n",
            "[ES] Iter 20/300\n",
            "[ES] Iter 40/300\n",
            "[ES] Iter 60/300\n",
            "[ES] Iter 80/300\n",
            "[ES] Iter 100/300\n",
            "[ES] Iter 120/300\n",
            "[ES] Iter 140/300\n",
            "[ES] Iter 160/300\n",
            "[ES] Iter 180/300\n",
            "[ES] Iter 200/300\n",
            "[ES] Iter 220/300\n",
            "[ES] Iter 240/300\n",
            "[ES] Iter 260/300\n",
            "[ES] Iter 280/300\n",
            "[ES] Seed 2 | Acc=0.5000 | F1=0.3333 | Time=5.04s\n",
            "\n",
            "==============================\n",
            "ES MULTI-RUN RESULTS\n",
            "Mean Accuracy: 0.5000 ¬± 0.0000\n",
            "Mean Time: 4.68s\n",
            "==============================\n",
            "\n",
            "\n",
            "=== ES Summary ===\n",
            "{'mean_accuracy': np.float64(0.5), 'std_accuracy': np.float64(0.0), 'mean_time': np.float64(4.6810634930928545), 'time': [4.5319459438323975, 4.471391916275024, 5.039852619171143], 'accuracies': [0.5, 0.5, 0.5]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Compute Cost for ES\n",
        "\n",
        "temp_model = ESClassifier()   # 768 ‚Üí 2 linear classifier\n",
        "\n",
        "compute_cost_summary(\n",
        "    temp_model,\n",
        "    float(np.mean(es_summary[\"time\"])),\n",
        "    trainable_params=count_parameters(temp_model, True)\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uwasApmgm7Xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76181657-f7cd-49be-8e69-89c11c39cf68"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Compute Cost ====================\n",
            "Total Parameters:        1,538\n",
            "Trainable Parameters:    1,538\n",
            "Training Time (seconds): 4.68\n",
            "Max GPU Memory (MB):     896.66\n",
            "Estimated FLOPs:         0.000 GFLOPs\n",
            "=====================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return ES model for final evaluation + error analysis\n",
        "def run_es_once_return_model(\n",
        "    seed,\n",
        "    num_iterations=100,\n",
        "    population_size=10,\n",
        "    learning_rate=1e-4,\n",
        "    noise_std=0.02,\n",
        "    reward_batches=1,\n",
        "):\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    model = ESClassifier().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = DataLoader(es_train_dataset, batch_size=32, shuffle=True)\n",
        "    train_iter = iter(train_loader)\n",
        "\n",
        "    print(f\"[ES-FINAL] Seed {seed} | Params={count_parameters(model):,}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "\n",
        "        batches = []\n",
        "        for _ in range(reward_batches):\n",
        "            try:\n",
        "                emb, y = next(train_iter)\n",
        "            except StopIteration:\n",
        "                train_iter = iter(train_loader)\n",
        "                emb, y = next(train_iter)\n",
        "            batches.append((emb.to(device), y.to(device)))\n",
        "\n",
        "        original = {n: p.clone() for n, p in model.named_parameters()}\n",
        "        rewards = []\n",
        "        noises = []\n",
        "\n",
        "        for _ in range(population_size):\n",
        "            noise = {n: torch.randn_like(p) * noise_std for n, p in original.items()}\n",
        "\n",
        "            # apply noise\n",
        "            with torch.no_grad():\n",
        "                for n, p in model.named_parameters():\n",
        "                    p.data = original[n] + noise[n]\n",
        "\n",
        "            losses = []\n",
        "            with torch.no_grad():\n",
        "                for emb, y in batches:\n",
        "                    logits = model(emb)\n",
        "                    loss = criterion(logits, y)\n",
        "                    losses.append(loss)\n",
        "\n",
        "            rewards.append(-torch.stack(losses).mean().item())\n",
        "            noises.append(noise)\n",
        "\n",
        "        rewards = torch.tensor(rewards)\n",
        "        if rewards.std() > 1e-6:\n",
        "            rewards = (rewards - rewards.mean()) / rewards.std()\n",
        "\n",
        "        # restore original weights\n",
        "        with torch.no_grad():\n",
        "            for n, p in model.named_parameters():\n",
        "                p.data = original[n]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # gradient estimate\n",
        "        for r, noise in zip(rewards, noises):\n",
        "            for n, p in model.named_parameters():\n",
        "                if p.grad is None:\n",
        "                    p.grad = torch.zeros_like(p)\n",
        "                p.grad += (noise[n] * r) / (population_size * noise_std)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"[ES-FINAL] Training complete in {total_time:.2f}s\")\n",
        "\n",
        "    # final metrics\n",
        "    results = evaluate_es_classifier(model, es_eval_dataset)\n",
        "    print(f\"[ES-FINAL] Acc={results['accuracy']:.4f} | F1={results['f1_score']:.4f}\")\n",
        "\n",
        "    return model, results\n"
      ],
      "metadata": {
        "id": "CLi-tLKeP9uX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error_analysis_embeddings(model, dataset, max_examples=5):\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, batch_size=64)\n",
        "\n",
        "    preds = []\n",
        "    labels = []\n",
        "    embeddings_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for emb, y in loader:\n",
        "            p = torch.argmax(model(emb.to(device)), dim=1)\n",
        "            preds.extend(p.cpu().numpy())\n",
        "            labels.extend(y.numpy())\n",
        "            embeddings_list.extend(emb.numpy())\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Confusion matrix\n",
        "    print(\"\\n================ Confusion Matrix ================\")\n",
        "    print(confusion_matrix(labels, preds))\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\n=============== Classification Report ===============\")\n",
        "    print(classification_report(labels, preds, digits=4))\n",
        "\n",
        "    # Misclassified examples\n",
        "    errors = np.where(preds != labels)[0]\n",
        "    print(\"\\n=============== Misclassified Embeddings ===============\")\n",
        "\n",
        "    if len(errors) == 0:\n",
        "        print(\"No misclassified examples.\")\n",
        "        return\n",
        "\n",
        "    for i, idx in enumerate(errors[:max_examples]):\n",
        "        print(f\"\\nExample #{i+1}\")\n",
        "        print(\"Predicted:\", preds[idx], \"| True:\", labels[idx])\n",
        "        print(\"Embedding snippet:\", embeddings_list[idx][:10], \"...\")"
      ],
      "metadata": {
        "id": "3PX0CuUp--B6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Error Analysis for ES (one final model)\n",
        "es_model_final, _ = run_es_once_return_model(\n",
        "    seed=123,\n",
        "    num_iterations=300,\n",
        "    population_size=20,\n",
        "    learning_rate=1e-4,\n",
        "    noise_std=0.02,\n",
        "    reward_batches=5\n",
        ")\n",
        "\n",
        "error_analysis_embeddings(\n",
        "    es_model_final,\n",
        "    es_eval_dataset,\n",
        "    max_examples=5\n",
        ")"
      ],
      "metadata": {
        "id": "BbO_4STx0IJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bc7d61-5e44-44f2-f773-59da940ceb40"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ES-FINAL] Seed 123 | Params=1,538\n",
            "[ES-FINAL] Training complete in 5.04s\n",
            "[ES-FINAL] Acc=0.5000 | F1=0.3333\n",
            "\n",
            "================ Confusion Matrix ================\n",
            "[[12500     0]\n",
            " [12500     0]]\n",
            "\n",
            "=============== Classification Report ===============\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    1.0000    0.6667     12500\n",
            "           1     0.0000    0.0000    0.0000     12500\n",
            "\n",
            "    accuracy                         0.5000     25000\n",
            "   macro avg     0.2500    0.5000    0.3333     25000\n",
            "weighted avg     0.2500    0.5000    0.3333     25000\n",
            "\n",
            "\n",
            "=============== Misclassified Embeddings ===============\n",
            "\n",
            "Example #1\n",
            "Predicted: 0 | True: 1\n",
            "Embedding snippet: [ 0.00907563 -0.14263205  0.07848252 -0.0630569   0.02283015 -0.22611223\n",
            "  0.22060768  0.25464037  0.02224126 -0.17812344] ...\n",
            "\n",
            "Example #2\n",
            "Predicted: 0 | True: 1\n",
            "Embedding snippet: [-0.15187225 -0.33934218 -0.27156308 -0.29645342  0.01914966 -0.02044361\n",
            "  0.39149427  0.04338212 -0.12081078 -0.08067421] ...\n",
            "\n",
            "Example #3\n",
            "Predicted: 0 | True: 1\n",
            "Embedding snippet: [-0.09876946 -0.24609047 -0.25878438 -0.36113504 -0.01403762  0.00143088\n",
            "  0.26251596  0.18318185 -0.09695735  0.04587926] ...\n",
            "\n",
            "Example #4\n",
            "Predicted: 0 | True: 1\n",
            "Embedding snippet: [-0.08037712 -0.1687747  -0.34273893 -0.30152732 -0.08090989 -0.02848384\n",
            "  0.30427092  0.16913909  0.03868752  0.04447728] ...\n",
            "\n",
            "Example #5\n",
            "Predicted: 0 | True: 1\n",
            "Embedding snippet: [-0.26009998 -0.21472359 -0.07143672 -0.31140706  0.2582732   0.00589316\n",
            "  0.38029215  0.10529003 -0.06677555 -0.176119  ] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}